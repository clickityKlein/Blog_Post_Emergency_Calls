{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690d1d33",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "We'll start off by importing the necessary libraries and modules. Unique to this notebook will be a separate notebook containing any\n",
    "functions required for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca8b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the standard libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95de5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the file containing our unique functions\n",
    "import nbimporter\n",
    "from blog_post_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe32e1",
   "metadata": {},
   "source": [
    "## Load Data and Perform Initial Inspection\n",
    "We gathered our data from https://data.seattle.gov/Public-Safety/Call-Data/33kz-ixgy, which provided a dataset named \"Call Data\" containing data on emergency calls to the Seattle Police Department call center.\n",
    "\n",
    "The dataset itself is just over 5 million rows, and very much so over GitHub's size limitation. The dataset we will be performing our analysis on is a subset containing 10,000 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT RUN!\n",
    "\n",
    "This cell will not run, it is only included to show how we obtained our subset.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('Call_Data.csv')\n",
    "\n",
    "np.random.seed(0)\n",
    "df_sample = np.random.choice(df.shape[0], 10000, replace = False)\n",
    "df_subset = df.loc[df_sample]\n",
    "\n",
    "df_subset.to_csv('Call_Data_Subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2966831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data (pretending we're starting with the 10,000 row dataset)\n",
    "df = pd.read_csv('Call_Data_Subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9469b",
   "metadata": {},
   "source": [
    "## Initial Inspection\n",
    "1. Check data types, and how it is all formatted.\n",
    "2. Check for missing values, and amount of missing values.\n",
    "3. Look for anything unique. Is there anything we haven't encountered before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the first few rows look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af7ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a8decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec3e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially hidden Missing Data: \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6395fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea62139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ab206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nulls and blanks in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143301b",
   "metadata": {},
   "source": [
    "## Potential Questions\n",
    "1. What time of the year / week / day do the majority of the calls come in?\n",
    "2. Do amount of calls / priority of calls change by precint, sector or beat?\n",
    "3. What determines priority?\n",
    "\n",
    "After performing some research on Computer-Aided-Dispatch systems (CAD), it appears the system itself assigns a Priority rating. Unfortunately, we're missing some of the datapoints actually used in assigning the Priority rating. However, let's see if how closely we can build a model that will predict Priority ratings.\n",
    "\n",
    "4. Can we buld a model to accurately predict Priority ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d980a",
   "metadata": {},
   "source": [
    "## Potential Question 1\n",
    "What time of the year / week / day do the majority of the calls come in?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27c3a8",
   "metadata": {},
   "source": [
    "## Potential Question 2\n",
    "Do amount of calls / priority of calls change by precint, sector or beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c15874",
   "metadata": {},
   "source": [
    "## Potential Question 3\n",
    "What determines priority?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f1d19",
   "metadata": {},
   "source": [
    "## Potential Question Freestyle\n",
    "Did we uncover anything interesting that we should explore further before building a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12561e0e",
   "metadata": {},
   "source": [
    "## Creating the Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11406c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
